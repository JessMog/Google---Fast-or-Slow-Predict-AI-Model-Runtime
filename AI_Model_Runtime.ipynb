{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQzD3syxDEM8ObxyNknmeX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JessMog/Google---Fast-or-Slow-Predict-AI-Model-Runtime/blob/main/AI_Model_Runtime.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MLOGNdjUn4X",
        "outputId": "9b509b54-3cd9-4a2b-f018-956428b68c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_gnn\n",
            "  Downloading tensorflow_gnn-1.0.2-py3-none-any.whl (838 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m838.4/838.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting apache-beam (from tensorflow_gnn)\n",
            "  Downloading apache_beam-2.55.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-vizier>=0.0.13 (from tensorflow_gnn)\n",
            "  Downloading google_vizier-0.1.15-py3-none-any.whl (761 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.6/761.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ml-collections (from tensorflow_gnn)\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from tensorflow_gnn) (3.2.1)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow_gnn) (14.0.2)\n",
            "Requirement already satisfied: tensorflow<2.16.0,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_gnn) (2.15.0)\n",
            "Collecting attrs==23.1.0 (from google-vizier>=0.0.13->tensorflow_gnn)\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.21.5 in /usr/local/lib/python3.10/dist-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.6 in /usr/local/lib/python3.10/dist-packages (from google-vizier>=0.0.13->tensorflow_gnn) (3.20.3)\n",
            "Requirement already satisfied: portpicker>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.5.2)\n",
            "Requirement already satisfied: grpcio>=1.35.0 in /usr/local/lib/python3.10/dist-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.62.1)\n",
            "Collecting grpcio-tools>=1.35.0 (from google-vizier>=0.0.13->tensorflow_gnn)\n",
            "  Downloading grpcio_tools-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos>=1.56.4 in /usr/local/lib/python3.10/dist-packages (from google-vizier>=0.0.13->tensorflow_gnn) (1.63.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4 in /usr/local/lib/python3.10/dist-packages (from google-vizier>=0.0.13->tensorflow_gnn) (2.0.29)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (0.36.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (2.15.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->tensorflow_gnn)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4,>=3.9.7 (from apache-beam->tensorflow_gnn)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam->tensorflow_gnn)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->tensorflow_gnn) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->tensorflow_gnn)\n",
            "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache-beam->tensorflow_gnn)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->tensorflow_gnn)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->tensorflow_gnn) (0.22.0)\n",
            "Collecting js2py<1,>=0.74 (from apache-beam->tensorflow_gnn)\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->tensorflow_gnn) (4.19.2)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->tensorflow_gnn) (3.0.3)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam->tensorflow_gnn)\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->tensorflow_gnn)\n",
            "  Downloading pymongo-4.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (676 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m676.9/676.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->tensorflow_gnn) (1.23.0)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->tensorflow_gnn) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->tensorflow_gnn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->tensorflow_gnn) (2023.4)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->tensorflow_gnn) (2023.12.25)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->tensorflow_gnn) (2.31.0)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam->tensorflow_gnn)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->tensorflow_gnn) (0.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml-collections->tensorflow_gnn) (6.0.1)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections->tensorflow_gnn) (21.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (0.43.0)\n",
            "Collecting protobuf>=3.6 (from google-vizier>=0.0.13->tensorflow_gnn)\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->tensorflow_gnn)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache-beam->tensorflow_gnn) (3.1.2)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam->tensorflow_gnn) (5.2)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache-beam->tensorflow_gnn)\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->tensorflow_gnn) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->tensorflow_gnn) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->tensorflow_gnn) (0.18.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker>=1.3.1->google-vizier>=0.0.13->tensorflow_gnn) (5.9.5)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->tensorflow_gnn)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->tensorflow_gnn) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4->google-vizier>=0.0.13->tensorflow_gnn) (3.0.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0,>=2.12.0->tensorflow_gnn) (3.2.2)\n",
            "Building wheels for collected packages: ml-collections, crcmod, dill, hdfs, pyjsparser, docopt\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=776da3ed1c365e61cba5eea81ee2c21169035cd409cdd1535bc973fb1b1f6e7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31409 sha256=5fcd0d195084163bf4e3ea709002197092c82fc8112d510462023240a94cef92\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78541 sha256=e92b09700a8d00bd25630b89378f1ea901bddb60df9f7be7049e2022604fba0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=5b2c31397bf99e2c603b7fd6b5df4601ffeada27522e8ff3bd68bcc7740e8e63\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25984 sha256=0a4f94f101ef8f4ab87248cb160474a0ef892344a5038f9ddbbdf9c7e31fbe20\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=5b114d3d61a2414e1c7b08bfaf037734250afd52829cdc2917636137fd6981cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built ml-collections crcmod dill hdfs pyjsparser docopt\n",
            "Installing collected packages: pyjsparser, docopt, crcmod, zstandard, protobuf, orjson, objsize, ml-collections, js2py, fasteners, fastavro, dnspython, dill, attrs, pymongo, hdfs, grpcio-tools, google-vizier, apache-beam, tensorflow_gnn\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.2.0\n",
            "    Uninstalling attrs-23.2.0:\n",
            "      Successfully uninstalled attrs-23.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache-beam-2.55.1 attrs-23.1.0 crcmod-1.7 dill-0.3.1.1 dnspython-2.6.1 docopt-0.6.2 fastavro-1.9.4 fasteners-0.19 google-vizier-0.1.15 grpcio-tools-1.62.1 hdfs-2.7.3 js2py-0.74 ml-collections-0.1.1 objsize-0.7.0 orjson-3.10.0 protobuf-4.25.3 pyjsparser-2.7.1 pymongo-4.6.3 tensorflow_gnn-1.0.2 zstandard-0.22.0\n",
            "Collecting tensorflow_ranking\n",
            "  Downloading tensorflow_ranking-0.5.5-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_ranking) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_ranking) (1.25.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_ranking) (1.16.0)\n",
            "Collecting tensorflow-serving-api<3.0.0,>=2.0.0 (from tensorflow_ranking)\n",
            "  Downloading tensorflow_serving_api-2.16.1-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: tensorflow<2.16.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_ranking) (2.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (4.25.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16.0->tensorflow_ranking) (2.15.0)\n",
            "INFO: pip is looking at multiple versions of tensorflow-serving-api to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading tensorflow_serving_api-2.14.1-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16.0->tensorflow_ranking) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16.0->tensorflow_ranking) (3.2.2)\n",
            "Installing collected packages: tensorflow-serving-api, tensorflow_ranking\n",
            "Successfully installed tensorflow-serving-api-2.14.1 tensorflow_ranking-0.5.5\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_gnn --pre\n",
        "!pip install tensorflow_ranking"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tpugraphsv1_layout_data_py\n",
        "!pip install tpugraphsv1_tile_data_py\n",
        "!pip install tpugraphsv1_implicit_py"
      ],
      "metadata": {
        "id": "jEb9wq2-D9IO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_gnn as tfgnn\n",
        "import tensorflow_ranking as tfr"
      ],
      "metadata": {
        "id": "sU93xecxc0qB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Pipelines\n",
        "The following code is organized as:\n",
        "\n",
        "Helper functions: MLP (_mlp) and Embedding layer (_Opembedding). The embedding layer amends a feature on the op nodes, with name op_e, by embedding the integral op IDs.\n",
        "Pipeline code for training on the Layout collections.\n",
        "Pipeline code for training on the Tile collection."
      ],
      "metadata": {
        "id": "lmPiJ9Ck6Nj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions, for both Layout and Tile collections."
      ],
      "metadata": {
        "id": "B_ZV9tZB4VQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _mlp(dims, hidden_activation, l2reg=1e-4, use_bias=True):\n",
        "  \"\"\"Helper function for multi-layer perceptron (MLP).\"\"\"\n",
        "  layers = []\n",
        "  for i, dim in enumerate(dims):\n",
        "    if i > 0:\n",
        "      layers.append(tf.keras.layers.Activation(hidden_activation))\n",
        "    layers.append(tf.keras.layers.Dense(\n",
        "        dim, kernel_regularizer=tf.keras.regularizers.l2(l2reg),\n",
        "        use_bias=use_bias))\n",
        "  return tf.keras.Sequential(layers)\n",
        "\n",
        "\n",
        "class _OpEmbedding(tf.keras.Model):\n",
        "  \"\"\"Embeds GraphTensor.node_sets['op']['op'] nodes into feature 'op_e'.\"\"\"\n",
        "\n",
        "  def __init__(self, num_ops: int, embed_d: int, l2reg: float = 1e-4):\n",
        "    super().__init__()\n",
        "    self.embedding_layer = tf.keras.layers.Embedding(\n",
        "        num_ops, embed_d, activity_regularizer=tf.keras.regularizers.l2(l2reg))\n",
        "\n",
        "  def call(\n",
        "      self, graph: tfgnn.GraphTensor,\n",
        "      training: bool = False) -> tfgnn.GraphTensor:\n",
        "    op_features = dict(graph.node_sets['op'].features)\n",
        "    op_features['op_e'] = self.embedding_layer(\n",
        "        tf.cast(graph.node_sets['op']['op'], tf.int32))\n",
        "    return graph.replace_features(node_sets={'op': op_features})"
      ],
      "metadata": {
        "id": "x8rnICoR4d7D"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layout Training Pipeline\n",
        "We start by defining constants:\n",
        "\n",
        "`Batch sizes = num graphs`, num sampled nodes per graph, and num configurations per graph.\n",
        "Collection to train on: source `(xla versus nlp)` and search stragey `(random versus default)`.\n",
        "Then, boilerplate code to prepare the datasets.\n",
        "\n",
        "Then, we dive deeper into the dataset examples `(a batch of graphs from the tiles collection)`.\n",
        "\n",
        "Finally, details on defining a model.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6RODZ2OX5SV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define constants and choose subcollection\n",
        "We load BATCH_SIZE graphs per batch. Each will have"
      ],
      "metadata": {
        "id": "WVSWCTJNE8kY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LAYOUT_DATA_ROOT = '/kaggle/input/predict-ai-model-runtime/npz_all/npz/layout'\n",
        "SOURCE = 'xla'  # Can be \"xla\" or \"nlp\"\n",
        "SEARCH = 'random'  # Can be \"random\" or \"default\"\n",
        "\n",
        "# Batch size information.\n",
        "BATCH_SIZE = 16  # Number of graphs per batch.\n",
        "CONFIGS_PER_GRAPH = 5  # Number of configurations (features and target values) per graph.\n",
        "MAX_KEEP_NODES = 1000  # Useful for dropout.\n",
        "# `MAX_KEEP_NODES` is (or, is not) useful for Segment Dropout, if model uses\n",
        "# edges \"sampled_config\" and \"sampled_feed\" (or, \"config\" and \"feed\")"
      ],
      "metadata": {
        "id": "JXiQXsRG5KDB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layout_data_root_dir = os.path.join(\n",
        "      os.path.expanduser(LAYOUT_DATA_ROOT), SOURCE, SEARCH)\n",
        "\n",
        "layout_npz_dataset = layout_data.get_npz_dataset(\n",
        "    layout_data_root_dir,\n",
        "    min_train_configs=CONFIGS_PER_GRAPH,\n",
        "    max_train_configs=500,  # If any graph has more than this configurations, it will be filtered [speeds up loading + training]\n",
        "    cache_dir='cache'\n",
        ")\n",
        "\n",
        "def pair_layout_graph_with_label(graph: tfgnn.GraphTensor):\n",
        "    \"\"\"Extracts label from graph (`tfgnn.GraphTensor`) and returns a pair of `(graph, label)`\"\"\"\n",
        "    # Return runtimes divded over large number: only ranking is required. The\n",
        "    # runtimes are in the 100K range\n",
        "    label = tf.cast(graph.node_sets['g']['runtimes'], tf.float32) / 1e7\n",
        "    return graph, label\n",
        "\n",
        "layout_train_ds = (\n",
        "      layout_npz_dataset.train.get_graph_tensors_dataset(\n",
        "          CONFIGS_PER_GRAPH, max_nodes=MAX_KEEP_NODES)\n",
        "      .shuffle(100, reshuffle_each_iteration=True)\n",
        "      .batch(BATCH_SIZE, drop_remainder=False)\n",
        "      .map(tfgnn.GraphTensor.merge_batch_to_components)\n",
        "      .map(pair_layout_graph_with_label))\n",
        "\n",
        "layout_valid_ds = (\n",
        "      layout_npz_dataset.validation.get_graph_tensors_dataset(\n",
        "          CONFIGS_PER_GRAPH)\n",
        "      .batch(BATCH_SIZE, drop_remainder=False)\n",
        "      .map(tfgnn.GraphTensor.merge_batch_to_components)\n",
        "      .map(pair_layout_graph_with_label))"
      ],
      "metadata": {
        "id": "jXIrAlGSEES5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare** `tf.data.Dataset` instances\n",
        "Specifically, `layout_train_ds` and `layout_valid_ds`.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "It can take ~10 minutes ."
      ],
      "metadata": {
        "id": "NIobeyxZFF0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layout_data_root_dir = os.path.join(\n",
        "      os.path.expanduser(LAYOUT_DATA_ROOT), SOURCE, SEARCH)\n",
        "\n",
        "layout_npz_dataset = layout_data.get_npz_dataset(\n",
        "    layout_data_root_dir,\n",
        "    min_train_configs=CONFIGS_PER_GRAPH,\n",
        "    max_train_configs=500,  # If any graph has more than this configurations, it will be filtered [speeds up loading + training]\n",
        "    cache_dir='cache'\n",
        ")\n",
        "\n",
        "def pair_layout_graph_with_label(graph: tfgnn.GraphTensor):\n",
        "    \"\"\"Extracts label from graph (`tfgnn.GraphTensor`) and returns a pair of `(graph, label)`\"\"\"\n",
        "    # Return runtimes divded over large number: only ranking is required. The\n",
        "    # runtimes are in the 100K range\n",
        "    label = tf.cast(graph.node_sets['g']['runtimes'], tf.float32) / 1e7\n",
        "    return graph, label\n",
        "\n",
        "layout_train_ds = (\n",
        "      layout_npz_dataset.train.get_graph_tensors_dataset(\n",
        "          CONFIGS_PER_GRAPH, max_nodes=MAX_KEEP_NODES)\n",
        "      .shuffle(100, reshuffle_each_iteration=True)\n",
        "      .batch(BATCH_SIZE, drop_remainder=False)\n",
        "      .map(tfgnn.GraphTensor.merge_batch_to_components)\n",
        "      .map(pair_layout_graph_with_label))\n",
        "\n",
        "layout_valid_ds = (\n",
        "      layout_npz_dataset.validation.get_graph_tensors_dataset(\n",
        "          CONFIGS_PER_GRAPH)\n",
        "      .batch(BATCH_SIZE, drop_remainder=False)\n",
        "      .map(tfgnn.GraphTensor.merge_batch_to_components)\n",
        "      .map(pair_layout_graph_with_label))"
      ],
      "metadata": {
        "id": "UXBOQjb4EFxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset cache file:  cache/317e146d60640edb255d1dcb2d3235c8-cache.npz\n",
        "100%|██████████| 69/69 [01:03<00:00,  1.09it/s]\n",
        "Saving ...\n",
        "wrote cache/317e146d60640edb255d1dcb2d3235c8-cache.npz\n",
        "wrote cache/317e146d60640edb255d1dcb2d3235c8-cache.npz.graphs.txt\n",
        "dataset cache file:  cache/ed1b35ba5a151cd92dc0e4d41f4160ce-cache.npz\n",
        "100%|██████████| 7/7 [00:07<00:00,  1.07s/it]\n",
        "Saving ...\n",
        "wrote cache/ed1b35ba5a151cd92dc0e4d41f4160ce-cache.npz\n",
        "wrote cache/ed1b35ba5a151cd92dc0e4d41f4160ce-cache.npz.graphs.txt\n",
        "dataset cache file:  cache/437403654dcd7a1b5d98d25edfb15ce6-cache.npz\n",
        "100%|██████████| 8/8 [00:01<00:00,  5.48it/s]\n",
        "Saving ...\n",
        "wrote cache/437403654dcd7a1b5d98d25edfb15ce6-cache.npz\n",
        "wrote cache/437403654dcd7a1b5d98d25edfb15ce6-cache.npz.graphs.txt"
      ],
      "metadata": {
        "id": "F39C4W8dF2HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cf7i_tqyF7IH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}